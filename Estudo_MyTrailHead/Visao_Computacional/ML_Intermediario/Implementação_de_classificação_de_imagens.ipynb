{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d9df470",
   "metadata": {},
   "source": [
    "# Implementação de classificação de imagens\n",
    "## Classificação de Imagens\n",
    "Neste módulo é possível acompanhar a implementação de um processo de classificação de imagens utilizando técnicas clássicas de Processamento Digital de Imagens e treinar classificadores para predição dos atributos.\n",
    "\n",
    "* **Módulos necessários**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83801a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2caf419",
   "metadata": {},
   "source": [
    "* **O Problema**\n",
    "Suponha que seja necessário identificação automática de uma figura geométrica por análise de imagens. As figuras que precisam ser identificadas estão definidas na Figura abaixo.\n",
    "\n",
    "![img_ref](img\\ref.JPG)\n",
    "\n",
    "Neste contexto, de forma automática, uma aplicação deve ser implementada de maneira que esta receba uma imagem e retorne o tipo de figura geométrica contida, com base no padrão definido [neste dataset](https://drive.google.com/file/d/1IiykLajz0zj5adY2wmGkmzUJ3K5sLPk7/view?usp=sharing).\n",
    "\n",
    "* **Preparando o dataset**\n",
    "Neste primeiro momento há necessidade de observar as imagens do dataset e organizá-las em uma estrutura de dados adequada para que seus atributos possam ser extraídos. há então a necessidade de carregar o conjunto de imagens via código. Abaixo segue um exemplo de uma função para carregar o conjunto de imagens e retornar estas estruturadas em lista e outra lista indicando classe de cada imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0729585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(datadir, classes, img_size=100):\n",
    "    training_data = []\n",
    "    label = []\n",
    "    for classe in range(len(classes)):\n",
    "        path = os.path.join(datadir, classes[classe])\n",
    "        shufled_list  = list(os.listdir(path))\n",
    "        shuffle(shufled_list)\n",
    "        for img in shufled_list:\n",
    "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            unique = np.unique(img_array)\n",
    "            if len(unique) == 1:\n",
    "                continue\n",
    "            training_data.append(img_array)\n",
    "            label.append(classe)\n",
    "    return training_data , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4df989",
   "metadata": {},
   "outputs": [],
   "source": [
    "data , label = load_data('dataset/geometric',['circle','square','star','triangle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5806f4",
   "metadata": {},
   "source": [
    "O código acima realiza a implementação de uma função que recebe 3 argumentos: o diretório que contem as pastas das imagens, uma lista de string que contém o nome das classes que devem ser reconhecidas e um parâmetro default que é o  tamanho da imagem que será utilizado em todo o processo. \n",
    "\n",
    "São definidas duas listas vazias *training_data* e *label*. Em training_data serão armazenadas as imagens e em label serão definidos números que representam cada classe. Deste modo, é possível saber a classe da imagem que estiver na posição 5 da lista training_data observando o número contido da quinta posição da lista *label*.\n",
    "\n",
    "Um loop for é realizado para iterar sobre as possíveis classes. Assim a variável *classe*,definida no loop, poderá assumir valores variando de  0 até 3, em que 0 representa classe 'circle' e 3 representa a classe 'triangle'. Na variável *path* é armazenada a string que contem o caminho para pasta de imagens da classe específica, conforme iteração do loop for e na estrutura shufled_list são contidas strings que são os caminhos de cada imagem da classe, já com um primeiro embaralhamento.\n",
    "\n",
    "O segundo loop for itera sobre os caminhos das imagens específicas e armazena estas em tom de cinza na variável img_array. A imagem é redimensionada, armazenada na lista training_data e variável classe é armazenada na lista label. Foi observado inconsistências neste dataset específico, em que há casos de imagens com um único tom de cinza. Estas são descartadas através da verificação junto a função *unique* da *numpy* auxiliada pelo comando *if*.\n",
    "\n",
    "* **Extração de atributos**\n",
    "\n",
    "De posse das imagens estruturadas, agora vamos extrair informações destas imagens para que estes dados sirvam de atributos. Neste caso a função features_extraction é responsável por isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a977f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contours_param(contour):\n",
    "    contour_area = contour[0].filled_area\n",
    "    contour_perimeter = contour[0].perimeter\n",
    "    contour_convex_area = contour[0].convex_area\n",
    "    diameter = contour[0].equivalent_diameter\n",
    "    return contour_area , contour_perimeter, contour_convex_area, diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be9787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(images):\n",
    "    features_list = []\n",
    "    for image in images:\n",
    "        thresh = threshold_otsu(image)\n",
    "        binary = np.array(image > thresh).astype(int)\n",
    "        white_pixel = np.where(binary > 0)\n",
    "        if len(white_pixel[0]) > 7000:\n",
    "            binary = abs(1-binary) # ajuste de imagens negativas\n",
    "        regions = regionprops(binary)\n",
    "        contour_area , contour_perimeter, contour_convex_area, diameter = get_contours_param(regions)\n",
    "        features_list.append([contour_area , contour_perimeter, contour_convex_area, diameter])\n",
    "    norm =  MaxAbsScaler()\n",
    "    norm.fit(features_list)\n",
    "    norm_features = norm.transform(features_list)\n",
    "    return norm_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8164ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_extraction(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca119c91",
   "metadata": {},
   "source": [
    "Nesta etapa, features_extraction recebe a lista de imagens que foi obtida em load_data. Nesta função é aplicada a limiarização de Otsu de forma iterativa com auxílio do loop for. Neste caso de imagens sintéticas, existe a possibilidade de o processo de limiarização de Otsu gerar imagens binarizadas, mas algumas sendo negativas. Assim é realizado a contagem de pixels brancos para garatir que estes componham o objeto e não o plano de fundo. Essa análise é específica para este dataset em particular. Essa lógica está implementada na analíse de white_pixels. Por isso, quando são contabilizados mais que 7000 pixels brancos, sugere-se que há caso de limiarização negativa.\n",
    "\n",
    "o Método regionprops é utilizado para segmentar as regiões geométricas da imagem. Contexto, a função get_contours_param é implementada para extrair os atributos do contorno. Ative o modo DEBUG da sua IDE para poder observar outros atributos que podem ser extraídos.\n",
    "\n",
    "Por fim, é realizada a normalização dos atributos para dimensionar cada atributo individualmente de modo que o valor absoluto máximo de cada um no conjunto de treinamento seja 1,0. A função MaxAbsScaler realiza isso.\n",
    "\n",
    "* **Treinamento e Teste dos Classificadores.**\n",
    "\n",
    "A variável features possui as os atributos extraídos das imagens. Neste contexto, a função gen_classifiers é iamplementada para retornar testes em 7 classificadores: Random Forest, MLP, KNN, SGDC, SVM, Árvore de decisão e Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa02b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_svm_model(train_data,label_train_data,test_data):\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_SGDC_model(train_data,label_train_data,test_data):\n",
    "    clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
    "    clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_naive_bayes_model(train_data,label_train_data,test_data):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, label_train_data)\n",
    "    predicted = gnb.predict(test_data)\n",
    "    return predicted\n",
    "def generate_decision_tree_model(train_data,label_train_data,test_data):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_data, label_train_data)\n",
    "    predicted = clf.predict(test_data)\n",
    "    return predicted\n",
    "def generate_random_forest_model(X_train, y_train,test_data):\n",
    "    rfc = RandomForestClassifier(criterion= 'entropy', max_depth= 8, max_features='auto', n_estimators=200)\n",
    "    rfc.fit(X_train,y_train)\n",
    "    predicted = rfc.predict(test_data)\n",
    "    return predicted\n",
    "def generate_MLP_model(X_train, y_train,test_data):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=300,activation = 'relu',solver='adam',random_state=1)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predicted = classifier.predict(test_data)\n",
    "    return predicted\n",
    "def generate_knn_model(train_data,label_train_data,test_data):\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(train_data,label_train_data)\n",
    "    predicted = knn.predict(test_data)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9d817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_classifiers(train_data,label_train_data,test_data):\n",
    "    return generate_knn_model(train_data,label_train_data,test_data),\\\n",
    "    generate_MLP_model(train_data,label_train_data,test_data),\\\n",
    "    generate_SGDC_model(train_data,label_train_data,test_data),\\\n",
    "    generate_svm_model(train_data,label_train_data,test_data),\\\n",
    "    generate_decision_tree_model(train_data,label_train_data,test_data),\\\n",
    "    generate_naive_bayes_model(train_data,label_train_data,test_data),\\\n",
    "    generate_random_forest_model(train_data,label_train_data,test_data),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b05475",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,label,test_size=0.3)\n",
    "results = gen_classifiers(X_train, y_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308e95b",
   "metadata": {},
   "source": [
    "A função divide o conjunto de atributos e labels em conjuntos de treino e teste para garantirmos que o processo de treinamento seja realizado com dados distintos dos que vão ser testados por cada classificador.\n",
    "\n",
    "Deste modo, a função gen_classifiers recebe os atributos de treinamento, as labels dos atributos de treinamento e os atribiutos de teste e retorna um array de valores que indicam os resultados dos testes de cada classificador. Cada classificador é inicializado com um objeto específico. Após a inicialização é realizado o comando fit para treinar o classificadorque recebe os atribiutos de treinamento e as labels dos atributos. Após o treinamento é realizado o comando predict para testar se o classificador realiza uma predição correta de atributos que não foram utilizados no conjunto de treinamento. A variável predicted é um vetor em que cada elemento do vetor é um valor que indica a classe a qual o atributo pertence. \n",
    "\n",
    "* **Avaliação dos classificadores**\n",
    "\n",
    "A biblioteca sklearn possui funções que auxiliam a medir quantitativamente o desempenho do classificador. A acurácia do classificador pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31139f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(test_labels, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3760ddb",
   "metadata": {},
   "source": [
    "![img_acc](img\\acc.JPG)\n",
    "\n",
    "VP = Verdadeiro positivo - objeto pertence a classe A e foi classificado na classe A\n",
    "\n",
    "VN = Verdadeiro negativo - objeto não pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "FP = Falso positivo - objeto não pertence a classe A e foi classificado na classe A\n",
    "\n",
    "FN = Falso negativo - objeto pertence a classe A e não foi classificado na classe A\n",
    "\n",
    "A sensibilidade/revocação/recall do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466ebc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = metrics.recall_score(y_test,results[0],average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ebeac",
   "metadata": {},
   "source": [
    "![img_rec](img\\rec.JPG)\n",
    "\n",
    "A precisão  do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73ccd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = metrics.precision_score(y_test,results[0],average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6007f",
   "metadata": {},
   "source": [
    "![img_prec](img\\prec.JPG)\n",
    "\n",
    "A métrica F1-Score do classificador, por classe,  pode ser medida pela chamada da função seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4233c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = metrics.f1_score(y_test,results[0],average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d4656",
   "metadata": {},
   "source": [
    "![img_pf1](img\\pf1.JPG)\n",
    "\n",
    "em resumo:\n",
    "\n",
    "* **Acurácia:** indica uma performance geral do modelo. Dentre todas as classificações, quantas o modelo classificou corretamente;\n",
    "* **Precisão:** dentre todas as classificações de classe Positivo que o modelo fez, quantas estão corretas;\n",
    "* **Recall/Revocação/Sensibilidade:** dentre todas as situações de classe Positivo como valor esperado, quantas estão corretas;\n",
    "* **F1-Score:** média harmônica entre precisão e recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
