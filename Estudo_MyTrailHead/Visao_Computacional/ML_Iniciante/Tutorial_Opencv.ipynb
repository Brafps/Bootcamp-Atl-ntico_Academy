{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84aec76a",
   "metadata": {},
   "source": [
    "# Tutorial Opencv\n",
    "\n",
    "Este tutorial apresenta conceitos introdutórios de processamento de imagens (filtros) e de visão computacional (segmentação, classificação, reconhecimento de padrão e rastreamento). Estes conceitos serão introduzidos utilizando a biblioteca OpenCV, que é distribuída gratuitamente e possui documentação farta na internet, com exemplos e aplicações práticas. Para utilizar essa biblioteca em python acesse o terminal com ambiente de python ativado e digite `pip install opencv-python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a51c26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_6396/3479432041.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Breno\\AppData\\Local\\Temp/ipykernel_6396/3479432041.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install opencv-python\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python\n",
    "pip install matplotlib.pyplot\n",
    "pip install numpy\n",
    "pip install mahotas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e0302",
   "metadata": {},
   "source": [
    "## 1. Lendo um documento e primeiras operações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d470619",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img](img\\img_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30af10f",
   "metadata": {},
   "source": [
    "Este  programa  abre  uma  imagem,  mostra  suas  propriedades  de  largura  e  altura  em pixels, mostra a quantidade de canais utilizados, mostra a imagem na tela, espera o pressionar de  alguma tecla  para  fechar  a  imagem  e  salva  em  disco  a  mesma  imagem  com  o  nome ‘saída.jpg’. Vamos explicar o código em detalhes no decorrer do texto. Mas vamos aplica-lo logo em uma imagem. \n",
    "\n",
    "É importante comentar que cada código abaixo foi rodado em uma IDE (pycharm ou vscode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84a256f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largura em pixels: 540\n",
      "Altura em pixels: 304\n",
      "Qtde de canais: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importação das bibliotecas\n",
    "import cv2\n",
    "\n",
    "# Leitura da imagem com a função imread()\n",
    "imagem = cv2.imread('ponte.jpg')\n",
    "\n",
    "print('Largura em pixels: ', end='')\n",
    "print(imagem.shape[1]) #largura da imagem (quantidade de colunas)\n",
    "\n",
    "print('Altura em pixels: ', end='')\n",
    "print(imagem.shape[0]) #altura da imagem (quantidade de linhas)\n",
    "\n",
    "print('Qtde de canais: ', end='')\n",
    "print(imagem.shape[2])\n",
    "\n",
    "# Mostra a imagem com a função imshow\n",
    "cv2.imshow(\"Ponte\", imagem)\n",
    "cv2.waitKey(0) #espera pressionar qualquer tecla\n",
    "# Salvar a imagem no disco com função imwrite()\n",
    "cv2.imwrite(\"saida.jpg\", imagem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31677242",
   "metadata": {},
   "source": [
    "Ao fim da excução teremos a mostra da janela abaixo\n",
    "\n",
    "![pega_na _pasta_img](pratica\\img_geradas\\saida.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea376b3",
   "metadata": {},
   "source": [
    "A importação da biblioteca padrão da OpenCV é obrigatória para utilizar suas funções. A primeira função usada é para abrir a imagem através de cv2.imread() que leva como argumento o nome do arquivo em disco. A imagem é lida e armazenada em ‘imagem’ que é uma variavel que dará acesso ao objeto da imagem que nada mais é que uma matriz de 3 dimensões (3 canais) contendo em cada dimensão uma das 3 cores do padrão RGB (red=vermelho, green-verde, blue=azul). No caso de uma imagem preto e branca temos apenas um canal, ou seja, apenas uma matriz de 2 dimensões. Para facilitar o entendimento podemos pensar em uma planilha eletrônica, com linhas e colunas, portanto, uma matriz de 2 dimensões. Cada célula dessa matriz é um pixel, que no caso de imagens preto e brancas possuem um valor de 0 a 255, sendo 0 para preto e 255 para branco. Portanto, cada célula contém um inteiro de 8 bits (sem sinal) que em Python é definido por “uint8” que é um unsigned integer de 8 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb48b6a",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img](img\\img_2.jpg)\n",
    "\n",
    "**Figura 1- Imagem preto e branca representada em uma matriz de inteiros onde cada célula é um inteiro sem sinal de 8 bits que pode conter de 0 (preto) até 255 (branco). Perceba os vários tons de cinza nos valores intermediários como 30 (cinza escuro) e 210 (cinza claro).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569d341",
   "metadata": {},
   "source": [
    "No  caso  de  imagens  preto  e  branca  é  composta  de  apenas  uma  matriz  de  duas  dimensões  como  na  imagem  acima.  Já  para  imagens  coloridas  temos  três  dessas  matrizes  de duas dimensões cada uma representando uma das cores do sistema RGB. Portanto, cada pixel é formado de uma tupla de 3 inteiros de 8 bits sem sinal no sistema (R,G,B) sendo que (0,0,0) representa o preto, (255,255,255) o branco. Nesse sentido, as cores mais comuns são:  \n",
    "\n",
    "Branco - RGB (255,255,255); \n",
    "\n",
    "Azul - RGB (0,0,255); \n",
    "\n",
    "Vermelho - RGB (255,0,0); \n",
    "\n",
    "Verde - RGB (0,255,0); \n",
    "\n",
    "Amarelo - RGB (255,255,0); \n",
    "\n",
    "Magenta - RGB (255,0,255); \n",
    "\n",
    " Ciano - RGB (0,255,255); \n",
    "\n",
    "Preto - RGB (0,0,0). \n",
    "\n",
    "As imagens coloridas, portanto, são compostas normalmente de 3 matrizes de inteiros  sem  sinal  de  8  bits,  a  junção  das  3  matrizes  produz  a  imagem  colorida  com  capacidade  de reprodução de 16,7 milhões de cores, sendo que os 8 bits tem capacidade para 256 valores e  elevando a 3 temos 256³ = 16,7 milhões. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fc2a0",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img](img\\img_3.jpg)\n",
    "\n",
    "**Figura 2- Na imagem temos um exemplo das 3 matrizes que compõe o sistema RGB. Cada pixel da imagem, portanto, é composto por 3 componentes de 8 bits cada, sem sinal, o que gera 256 combinações por cor. Portanto, a representação é de 256 vezes 256 vezes 256 ou 256³ que é igual a 16,7 milhões de cores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2f765",
   "metadata": {},
   "source": [
    "## 2. Sistema de coordenadas e manipulação de pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6297ff2",
   "metadata": {},
   "source": [
    "Podemos  alterar  a  cor  individualmente  para  cada  pixel, ou seja, podemos manipular individualmente cada pixel da imagem.  Para isso é importante entender o sistema de coordenadas (linha, coluna) onde o pixel mais a esquerda e acima da imagem esta na posição (0,0) esta na linha zero e coluna zero. Já em uma imagem com 300 pixels de largura, ou seja, 300 colunas e tendo 200 pixels de altura,  ou  seja,  200  linhas,  terá  o  pixel  (199,299)  como  sendo  o  pixel  mais  a  direita  e  abaixo  da imagem.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7244642",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img](img\\img_4.jpg)\n",
    "\n",
    "**Figura 5 Imagem completamente azul pela alteração de todos os pixels para (255,0,0). Lembrando que o  padrão RGB é na verdade BRG pela tupla (B, R, G).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71aded",
   "metadata": {},
   "source": [
    "A partir do entendimento do sistema de coordenadas é possível alterar individualmente cada pixel ou ler a informação individual do pixel conforme abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagem = cv2.imread('ponte.jpg') \n",
    "(b, g, r) = imagem[0, 0] #veja que a ordem BGR e não RGB\n",
    "\n",
    "#Uma observação que podemos fazer aqui é a equivalencia entre imagem[y, x] com imagem[y][x]\n",
    "\n",
    "print(len(imagem[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80583994",
   "metadata": {},
   "source": [
    "Imagens são matrizes Numpy neste caso retornadas pelo método “imread” e armazenada em memória através da variável “imagem” conforme acima. Lembre-se que o pixel superior mais a esquerda é o (0,0). No código é retornado na tupla (b, g, r) os respectivos valores das cores do pixel superior mais a esquerda. Veja que o método retorna a sequência BGR e não RGB como poderiamos esperar. Tendo os valores inteiros de cada cor é possível exibi-los na tela com o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4314099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('O pixel (0, 0) tem as seguintes cores:') \n",
    "print('Vermelho:', r, 'Verde:', g, 'Azul:', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14eab7",
   "metadata": {},
   "source": [
    "Outra possibilidade é utilizar dois laços de repetição para “varrer” todos os pixels da  imagem, linha por linha como é o caso do código abaixo. Importante notar que esta estratégia pode  não  ser  muito  performática  já  que  é  um  processo  lento  varrer  toda  a imagem  pixel  a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b395a7ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saida_azul' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6396/2175252972.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mimagem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Imagem modificada\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaida_azul\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saida_azul' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "imagem = cv2.imread('ponte.jpg') \n",
    "for y in range(0, imagem.shape[0]):\n",
    "    for x in range(0, imagem.shape[1]):\n",
    "        imagem[y, x] = (255,0,0)\n",
    "cv2.imshow(\"Imagem modificada\", saida_azul)\n",
    "cv2.waitKey(0) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14235169",
   "metadata": {},
   "source": [
    "O resultado é uma imagem com todos os pixels substituídos pela cor azul (255,0,0), como mostra a janela abaixo:\n",
    "\n",
    "\n",
    "![pega_na _pasta_img](Prática\\img_geradas\\Imagem_modificada.jpg)\n",
    "\n",
    "**Figura 5 Imagem completamente azul pela alteração de todos os pixels para (255,0,0). Lembrando que o  padrão RGB é na verdade BRG pela tupla (B, R, G).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b9d88",
   "metadata": {},
   "source": [
    "Com uma  modificação temos o código abaixo. O objetivo agora é saltar  a cada 10 pixels ao percorrer as linhas e mais 10 pixels ao percorrer as colunas. A cada salto é criado um quadrado amarelo de 5x5 pixels. Desta vez parte da imagem original é preservada e  podemos ainda observar a ponte por baixo da grade de quadrados amarelos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "imagem = cv2.imread('ponte.jpg') \n",
    "for y in range(0, imagem.shape[0], 10): #percorre linhas\n",
    "    for x in range(0, imagem.shape[1], 10): #percorre colunas\n",
    "        imagem[y:y+5, x: x+5] = (0,255,255)\n",
    "cv2.imshow(\"Imagem modificada\", imagem) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925700a9",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img](Pratica\\img_geradas\\quadrados_amarelos.jpg)\n",
    "\n",
    "**Figura 6 Código gerou quadrados amarelos de 5x5 pixels sobre a toda a imagem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6526d",
   "metadata": {},
   "source": [
    "é de grande importância entender o sistema de coordenadas em uma imagem, tendo em vista os cortes que podemos fazer na mesma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f5ec9",
   "metadata": {},
   "source": [
    "## 3. Cortando uma imagem / Crop\n",
    "Veja  o  código  abaixo onde criamos uma nova imagem a partir de um pedaço da imagem original (ROI) e a salvamos no\n",
    "disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf74c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "imagem = cv2.imread('ponte.jpg')\n",
    "recorte = imagem[100:200, 100:200]\n",
    "cv2.imshow(\"Recorte da imagem\", recorte)\n",
    "cv2.imwrite(\"img/recorte.jpg\", recorte) #salva no disco "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a65cfa",
   "metadata": {},
   "source": [
    "![pega_na _pasta_img_geradas](Pratica\\img\\recorte.jpg)\n",
    "\n",
    "**Figura 7 Imagem recortada da imagem original**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aaf1b8",
   "metadata": {},
   "source": [
    "## 4. Redimensionamento / Resize\n",
    "Para  reduzir  ou  aumentar  o  tamanho  da  imagem,  existe  uma  função  já  pronta  da OpenCV, trata-se da função ‘resize’ mostrada abaixo. Importante notar que é preciso calcular\n",
    "a proporção da altura em relação a largura da nova imagem, caso contrário ela poderá ficar distorcida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d883404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('ponte.jpg')\n",
    "cv2.imshow(\"Original\", img)\n",
    "largura = img.shape[1]\n",
    "altura = img.shape[0]\n",
    "proporcao = float(altura/largura)\n",
    "largura_nova = 320 #em pixels\n",
    "altura_nova = int(largura_nova*proporcao)\n",
    "tamanho_novo = (largura_nova, altura_nova)\n",
    "img_redimensionada = cv2.resize(img,\n",
    "tamanho_novo, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Resultado', img_redimensionada)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7ecef",
   "metadata": {},
   "source": [
    "pegar imagem\n",
    "\n",
    "**Figura 8 - No canto inferior esquerdo da imagem é possível notar a imagem redimensionada.**\n",
    "\n",
    "Veja  que  a  função  ‘rezise’  utiliza  uma  propriedade  aqui  definida  com cv2.INTER_AREA  que  é  uma  especificação  do  cálculo  matemático  para  redimensionar  a\n",
    "imagem. Apesar disso, caso a imagem seja redimensionada para um tamanho maior é preciso ponderar que ocorrerá perda de qualidade.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a37d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 img = cv2.imread('ponte.jpg') \n",
    "cv2.imshow(\"Original\", img) \n",
    "flip_horizontal = img[::-1,:]#comando equivalente abaixo \n",
    "#flip_horizontal = cv2.flip(img, 1)  \n",
    "cv2.imshow(\"Flip Horizontal\", flip_horizontal) \n",
    "flip_vertical = img[:,::-1] #comando equivalente abaixo \n",
    "#flip_vertical = cv2.flip(img, 0)  \n",
    "cv2.imshow(\"Flip Vertical\", flip_vertical) \n",
    "flip_hv = img[::-1,::-1] #comando equivalente abaixo  \n",
    "#flip_hv = cv2.flip(img, -1) \n",
    "cv2.imshow(\"Flip Horizontal e Vertical\", flip_hv) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8474e",
   "metadata": {},
   "source": [
    "**Figura 9 Resultado do flip horizontal, vertical e horizontal e vertical na mesma imagem.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d6e31",
   "metadata": {},
   "source": [
    "## 5. Rotacionando uma imagem / Rotate  \n",
    "A  transformação  affine  ou  mapa  affine,  é  uma  função  entre  espaços  affine  que preservam  os  pontos,  grossura  de  linhas  e  planos.  Além  disso,  linhas  paralelas  permanecem\n",
    "paralelas após uma transformação affine. Essa transformação não necessariamente preserva a distância entre pontos mas ela preserva a proporção das distâncias entre os pontos de uma\n",
    "linha reta. Uma rotação é um tipo de transformação affine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg') \n",
    "(alt, lar) = img.shape[:2] #captura altura e largura \n",
    "centro = (lar // 2, alt // 2) #acha o centro  \n",
    "M = cv2.getRotationMatrix2D(centro, 30, 1.0)#30 graus \n",
    "img_rotacionada = cv2.warpAffine(img, M, (lar, alt))  \n",
    "cv2.imshow(\"Imagem rotacionada em 30 graus\", img_rotacionada) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40023c6",
   "metadata": {},
   "source": [
    "**Figura 10 Imagem rotacionada em 30 graus.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cbd0b0",
   "metadata": {},
   "source": [
    "## 6. Sistemas de cores \n",
    "Já  conhecemos  o  tradicional  espaço  de  cores  RGB  (Red,  Green,  Blue)  que  sabemos que  em  OpenCV  é  na  verdade  BGR  dada  a  necessidade  de  colocar  o  azul  como  primeiro elemento e o vermelho como terceiro elemento de uma tupla que compõe as cores de pixel.  \n",
    "\n",
    "Contudo, existem outros espaços de cores como o próprio “Preto e Branco” ou “tons de cinza”, além de outros coloridos como o L*a*b* e o HSV. Abaixo temos um exemplo de\n",
    "como ficaria nossa imagem da ponte nos outros espaços de cores :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d0cf9",
   "metadata": {},
   "source": [
    "**Figura 11 Outros espaços de cores com a mesma imagem.** \n",
    "\n",
    "Segue código para exibir imagens em outros formatos, alem do RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ac645",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg')\n",
    "cv2.imshow(\"Original\", img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"HSV\", hsv)\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow(\"L*a*b*\", lab)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255a6241",
   "metadata": {},
   "source": [
    "Como  já  sabemos  uma  imagem  colorida  no  formato  RGB  possui  3  canais,  um  para cada  cor.  Existem  funções  do  OpenCV  que  permitem  separar  e  visualizar  esses  canais\n",
    "individualmente. Veja: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fff7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg') \n",
    "(canalAzul, canalVerde, canalVermelho) = cv2.split(img)\n",
    "cv2.imshow(\"Vermelho\", canalVermelho) \n",
    "cv2.imshow(\"Verde\", canalVerde) \n",
    "cv2.imshow(\"Azul\", canalAzul) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016b40c4",
   "metadata": {},
   "source": [
    "A função ‘split’ faz o trabalho duro separando os canais. Assim podemos exibi-los em tons de cinza conforme mostra a imagem abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d3577",
   "metadata": {},
   "source": [
    "**Figura 12 Perceba como a linha amarela (que é formada por verde e vermelho) fica quase imperceptível\n",
    "no canal azul.** \n",
    "\n",
    "Também é possível alterar individualmente as Numpy Arrays que formam cada canal e depois juntá-las para criar novamente a imagem. Para isso use o comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = cv2.merge([canalAzul, canalVerde, canalVermelho]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09754a",
   "metadata": {},
   "source": [
    "Também é possível exibir os canais nas cores originais conforme abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06498f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "img = cv2.imread('ponte.jpg')  \n",
    "(canalAzul, canalVerde, canalVermelho) = cv2.split(img)  \n",
    "zeros = np.zeros(img.shape[:2], dtype = \"uint8\")  \n",
    "cv2.imshow(\"Vermelho\", cv2.merge([zeros, zeros, canalVermelho]))  \n",
    "cv2.imshow(\"Verde\", cv2.merge([zeros, canalVerde, zeros])) \n",
    "cv2.imshow(\"Azul\", cv2.merge([canalAzul, zeros, zeros])) \n",
    "cv2.imshow(\"Original\", img) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990f9c3",
   "metadata": {},
   "source": [
    "**Figura 13 Exibindo os canais separadamente.**  \n",
    "\n",
    "## 7. Histogramas e equalização de imagem  \n",
    "Um histograma é um gráfico de colunas ou de linhas que representa a distribuição dos valores dos pixels de uma imagem, ou seja, a quantidade de pixeis mais claros (próximos de 255) e a quantidade de pixels mais escuros (próximos de 0). O eixo X do gráfico normalmente possui uma distribuição de 0 a 255 que demonstra o valor (intensidade) do pixel e no eixo Y é plotada a quantidade de pixels daquela intensidade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520df5b",
   "metadata": {},
   "source": [
    "**Figura 14 Imagem original já convertida para tons de cinza** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4a3d5",
   "metadata": {},
   "source": [
    "**Figura 15 Histograma da imagem em tons de cinza.**\n",
    "\n",
    "Perceba  que  no  histograma  existe  um  pico  ao  centro  do  gráfico,  entre  100  e  150,  demonstrando  a  grande  quantidade  de  pixels  nessa  faixa  devido  a  estrada  que  ocupa  grande\n",
    "parte da imagem possui pixels nessa faixa.\n",
    "O código para gerar o histograma segue abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "import cv2  \n",
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #converte P&B \n",
    "cv2.imshow(\"Imagem P&B\", img) \n",
    "#Função calcHist para calcular o histograma da imagem \n",
    "h = cv2.calcHist([img], [0], None, [256], [0, 256]) \n",
    "plt.figure() \n",
    "plt.title(\"Histograma P&B\") \n",
    "plt.xlabel(\"Intensidade\") \n",
    "plt.ylabel(\"Qtde de Pixels\") \n",
    "plt.plot(h) \n",
    "plt.xlim([0, 256]) \n",
    "plt.show() \n",
    "cv2.waitKey(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515b6ed",
   "metadata": {},
   "source": [
    "Também  é  possível  plotar  o  histograma  de  outra  forma,  com  a  ajuda  da  função ‘ravel()’. Neste caso o eixo X avança o valor 255 indo até 300, espaço que não existem pixels.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img.ravel(),256,[0,256]) plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83812d6",
   "metadata": {},
   "source": [
    "**Figura 16 Histograma em barras.**  \n",
    "\n",
    "Além do histograma da imagem em tons de cinza é possível plotar um histograma da imagem colorida. Neste caso teremos três linhas, uma para cada canal. Veja abaixo o código \n",
    "\n",
    "necessário.  Importante notar que a função ‘zip’ cria uma lista de tuplas formada  pelas  união das  listas  passadas  e  não  tem  nada  a  ver  com  um  processo  de  compactação  como  poderia  se esperar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('ponte.jpg')\n",
    "cv2.imshow(\"Imagem Colorida\", img)\n",
    "#Separa os canais\n",
    "canais = cv2.split(img)\n",
    "cores = (\"b\", \"g\", \"r\")\n",
    "plt.figure()\n",
    "plt.title(\"'Histograma Colorido\")\n",
    "plt.xlabel(\"Intensidade\")\n",
    "plt.ylabel(\"Número de Pixels\")\n",
    "for (canal, cor) in zip(canais, cores):\n",
    "#Este loop executa 3 vezes, uma para cada canal\n",
    "hist = cv2.calcHist([canal], [0], None, [256], [0, 256])\n",
    "plt.plot(hist, cor = cor)\n",
    "plt.xlim([0, 256])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b31cb",
   "metadata": {},
   "source": [
    "**Figura 17 Histograma colorido da imagem. Neste caso são plotados os 3 canais RGB.**  \n",
    "\n",
    "## 8.Equalização de Histograma \n",
    "É possível realizar um cálculo matemático sobre a distribuição de pixels para aumentar o contraste da imagem. A intenção neste caso é distribuir de forma mais uniforme as\n",
    "intensidades dos pixels sobre a imagem. No histograma é possível identificar a diferença pois o acumulo de pixels próximo a alguns valores é suavizado. Veja a diferença entre o\n",
    "histograma original e o equalizado abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af021d6",
   "metadata": {},
   "source": [
    "**Figura 18 Histograma da imagem original.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af16ed",
   "metadata": {},
   "source": [
    "**Figura 19 Histograma equalizado.**\n",
    "\n",
    "O código utilizado para gerar os dois histogramas segue abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('ponte.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "h_eq = cv2.equalizeHist(img)\n",
    "plt.figure()\n",
    "plt.title(\"Histograma Equalizado\")\n",
    "plt.xlabel(\"Intensidade\")\n",
    "plt.ylabel(\"Qtde de Pixels\")\n",
    "plt.hist(h_eq.ravel(), 256, [0,256])\n",
    "plt.xlim([0, 256])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.title(\"Histograma Original\")\n",
    "plt.xlabel(\"Intensidade\")\n",
    "plt.ylabel(\"Qtde de Pixels\")\n",
    "plt.hist(img.ravel(), 256, [0,256])\n",
    "plt.xlim([0, 256])\n",
    "plt.show()\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1fa18",
   "metadata": {},
   "source": [
    "Na imagem a diferença também é perceptível, veja:\n",
    "\n",
    "[fig](fig)\n",
    "\n",
    "**Figura 20 Imagem original (acima) e imagem cujo histograma foi equalizado (abaixo). Na imagem cujo histograma foi equalizado percebemos maior contraste.**  \n",
    "\n",
    "## 9. Suavização de imagens\n",
    "A  suavização  da  imagem  (do  inglês  Smoothing),  também  chamada  de  ‘blur’  ou ‘blurring’ que podemos traduzir para “borrão”, é um efeito que podemos notar nas fotografias fora de foco ou desfocadas onde tudo fica embasado. Na  verdade  esse  efeito  pode  ser  criado  digitalmente,  basta  alterar  a  cor  de  cada  pixel misturando  a  cor  com  os  pixels  ao  seu  redor.  Esse  efeito  é  muito  útil  quando  utilizamos algoritmos  de  identificação  de  objetos  em  imagens  pois  os  processos  de  detecção  de  bordas por exemplo, funcionam melhor depois de aplicar uma suavização na imagem.\n",
    "\n",
    "## 10.Suavização por cálculo da média\n",
    " Neste caso é criada uma “máscara para envolver o pixel em questão e calcular seu novo valor. O novo valor do pixel será a média simples dos valores dos pixels dentro da máscara,  ou  seja,  dos  pixels  da  vizinhança.  Alguns  autores  chamam  esta  máscara  de  janela  de cálculo ou kernel (do inglês núcleo).\n",
    " \n",
    "[fig](fig) \n",
    " \n",
    "**Figura 21 Máscara 3x3 pixels. O número de linhas e colunas da caixa  deve ser ímpar para que existe sempre o pixel central que será alvo do cálculo.**  \n",
    "\n",
    "Portanto o novo valor do pixel será a média da sua vizinhança o que gera a suavização na imagem como um todo.  No código abaixo percebemos que o método utilizado para a suavização pela média é o  método  ‘blur’  da  OpenCV.  Os  parâmetros  são  a  imagem  a  ser  suavizada  e  a  janela  de suavização. Colocarmos números impars para gerar as caixas de cálculo pois dessa forma não existe dúvida sobre onde estará o pixel central que terá seu valor atualizado.  Perceba que usamos as funções vstack (pilha vertical) e hstack (pilha horizontal) para juntar as imagens em uma única imagem final mostrando desde a imagem original e seguinte com caixas de calculo de 3x3, 5x5, 7x7, 9x9 e 11x11. Perceba que conforme aumenta a caixa maior é o efeito de borrão (blur) na imagem.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg') \n",
    "img = img[::2,::2] # Diminui a imagem  \n",
    "suave = np.vstack([   np.hstack([img,cv2.blur(img, ( 3,  3))]),np.hstack([cv2.blur(img, (5,5)), cv2.blur(img, ( 7,  7))]),np.hstack([cv2.blur(img, (9,9)), cv2.blur(img, (11, 11))]),])  \n",
    "cv2.imshow(\"Imagens suavisadas (Blur)\", suave) \n",
    "cv2.waitKey(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe429cdb",
   "metadata": {},
   "source": [
    "**Figura 22 Imagem original seguida da esquerda para a direita e de cima para baixo com imagens tendo caixas de cálculo de 3x3, 5x5, 7x7, 9x9 e 11x11. Perceba que conforme aumenta a caixa maior é o efeito de borrão (blur) na imagem.**  \n",
    "\n",
    "## 11. Suavização pela mediana\n",
    "Da  mesma  forma  que  os  cálculos  anteriores,  aqui  temos  o  cálculo  de  uma  caixa  ou  janela  quadrada  sobre  um  pixel  central  onde  matematicamente  se  utiliza  a  mediana  para \n",
    "\n",
    "calcular o valor final do pixel. A mediana é semelhante à média, mas ela despreza os valores muito altos ou muito baixos que podem distorcer o resultado. A mediana é o número que fica \n",
    "\n",
    "exatamente no meio do intervalo. A  função  utilizada  é  a  cv2.medianBlur(img,  3)  e  o  único  argumento  é  o  tamanho  da caixa ou janela usada. É importante notar que este método não cria novas cores, como pode acontecer com os anteriores, pois ele sempre altera a cor do pixel atual com um dos valores da vizinhança. \n",
    "\n",
    "Veja o código usado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432658d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('ponte.jpg')\n",
    "img = img[::2,::2] # Diminui a imagem\n",
    "suave = np.vstack([\n",
    "np.hstack([img,\n",
    "cv2.medianBlur(img,  3)]),\n",
    "np.hstack([cv2.medianBlur(img,  5),\n",
    "cv2.medianBlur(img,  7)]),\n",
    "np.hstack([cv2.medianBlur(img,  9),\n",
    "cv2.medianBlur(img, 11)]),\n",
    "])\n",
    "cv2.imshow(\"Imagem original e suavizadas pela mediana\", suave)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d3838",
   "metadata": {},
   "source": [
    "**Figura 23 Da mesma forma temos a imagem original seguida pelas imagens alteradas pelo filtro de mediana com o tamanho de 3, 5, 7, 9, e 11 nas caixas de cálculo.** \n",
    "\n",
    "## 12. Suavização com filtro bilateral  \n",
    "Este  método  é  mais  lento  para calcular  que os  anteriores  mas  como  vantagem apresenta a preservação de bordas e garante que o ruído seja removido.  \n",
    "\n",
    "Para  realizar  essa  tarefa,  além  de  um  filtro  gaussiano  do  espaço  ao  redor  do  pixel também é utilizado outro cálculo com outro filtro gaussiano que leva em conta a diferença de \n",
    "\n",
    "intensidade  entre  os  pixels,  dessa  forma,  como  resultado  temos  uma  maior  manutenção  das bordas das imagem. A função usada é cv2.bilateralFilter() e o código usado segue abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3edeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg')\n",
    "img = img[::2,::2] # Diminui a imagem\n",
    "suave = np.vstack([\n",
    "np.hstack([img,\n",
    "cv2.bilateralFilter(img,  3, 21, 21)]),\n",
    "np.hstack([cv2.bilateralFilter(img,  5, 35, 35),\n",
    "cv2.bilateralFilter(img,  7, 49, 49)]),\n",
    "np.hstack([cv2.bilateralFilter(img,  9, 63, 63),\n",
    "cv2.bilateralFilter(img, 11, 77, 77)])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185be56",
   "metadata": {},
   "source": [
    "**Figura 24 Imagem original e imagens alteradas pelo filtro bilateral. Veja como mesmo com a grande interferência na imagem no caso da imagem mais à baixo e à direita as bordas são preservadas.** \n",
    "\n",
    "## 13. Binarização com limiar\n",
    "Thresholding  pode  ser  traduzido  por  limiarização  e  no  caso  de  processamento  de imagens  na  maior  parte  das  vezes  utilizamos  para  binarização  da  imagem.  Normalmente\n",
    "convertemos  imagens  em  tons  de  cinza  para  imagens  preto  e  branco  onde  todos  os  pixels possuem 0 ou 255 como valores de intensidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur  (\n",
    "T, bin) = cv2.threshold(suave, 160, 255, cv2.THRESH_BINARY) \n",
    "(T, binI) = cv2.threshold(suave, 160, 255, cv2.THRESH_BINARY_INV) \n",
    "resultado = np.vstack([  np.hstack([suave, bin]),  np.hstack([binI, cv2.bitwise_and(img, img, mask = binI)])  ])   \n",
    "cv2.imshow(\"Binarização da imagem\", resultado) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5b9e4",
   "metadata": {},
   "source": [
    "No  código  realizamos  a  suavização  da  imagem,  o  processo  de  binarização  com   threshold de 160 e a inversão da imagem binarizada. \n",
    "\n",
    "[fig](fig)\n",
    "\n",
    "**Figura 25 Da esquerda para a direta e de cima para baixo temos: a imagem, a imagem suavizada, a imagem binarizada e a imagem binarizada invertida.**  \n",
    "\n",
    "No  caso  das  estradas,  esta  é  uma  das  técnicas  utilizadas  por  carros  autônomos  para identificar a pista. A mesma técnica também é utilizada para identificação de objetos.\n",
    "\n",
    "## 14. Threshold adaptativo  \n",
    "O valor de intensidade 160 utilizada para a binarização acima foi arbitrado, contudo, é possível otimizar esse valor matematicamente. Esta é a proposta do threshold adaptativo.  \n",
    "Para isso precisamos dar um valor da janela ou caixa de cálculo para que o limiar seja calculado nos pixels próximos das imagem. Outro parâmetro é um inteiro que é subtraído da\n",
    "média calculada dentro da caixa para gerar o threshold final.\n",
    "\n",
    "[fig](fig)\n",
    "\n",
    "Figura 26 Threshold adaptativo. Da esquerda para a direta e de cima para baixo temos: a imagem, a imagem suavizada, a imagem binarizada pela média e a imagem binarizada com Gauss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5739c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converte  \n",
    "suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur   \n",
    "bin1 = cv2.adaptiveThreshold(suave, 255,  cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 5) \n",
    "bin2 = cv2.adaptiveThreshold(suave, 255,  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,          21, 5)  \n",
    "resultado = np.vstack([  np.hstack([img, suave]),  np.hstack([bin1, bin2])  ])   \n",
    "cv2.imshow(\"Binarização adaptativa da imagem\", resultado) \n",
    "cv2.waitKey(0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe818c",
   "metadata": {},
   "source": [
    "## 15. Threshold com Otsu e Riddler-Calvard\n",
    "Outro método que automaticamente encontra um threshold para a imagem é o método de Otsu. Neste caso ele analiza o histograma da imagem para encontrar os dois maiores picos\n",
    "de intensidades, então ele calcula um valor para separar da melhor forma esses dois picos.\n",
    "\n",
    "**Figura 27 Threshold com Otsu e Riddler-Calvard.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas \n",
    "import numpy as np \n",
    "import cv2  \n",
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # converte  \n",
    "suave = cv2.GaussianBlur(img, (7, 7), 0) # aplica blur  \n",
    "T = mahotas.thresholding.otsu(suave) \n",
    "temp = img.copy() \n",
    "temp[temp > T] = 255 \n",
    "temp[temp < 255] = 0 \n",
    "temp = cv2.bitwise_not(temp) \n",
    "T = mahotas.thresholding.rc(suave) \n",
    "temp2 = img.copy() \n",
    "temp2[temp2 > T] = 255 \n",
    "temp2[temp2 < 255] = 0 \n",
    "temp2 = cv2.bitwise_not(temp2) \n",
    "resultado = np.vstack([  np.hstack([img, suave]),  np.hstack([temp, temp2])  ])  \n",
    "cv2.imshow(\"Binarização com método Otsu e Riddler-Calvard\", resultado) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec092a9",
   "metadata": {},
   "source": [
    "## 16. Segmentação e métodos de detecção de bordas\n",
    "Uma  das  tarefas  mais  importantes  para  a  visão  computacional  é  identificar  objetos. Para essa identificação uma das principais técnicas é a utilização de detectores de bordas a fim\n",
    "de identificar os formatos dos objetos presentes na imagem. Quando falamos em segmentação e detecção de bordas, os algoritmos mais comuns são o Canny, Sobel e variações destes. Basicamente nestes e em outros métodos a detecção de bordas se faz através de identificação do gradiente, ou, neste caso, de variações abruptas na\n",
    "intensidade dos pixels de uma região da imagem. A OpenCV disponibiliza a implementação de 3 filtros de gradiente (High-pass filters): Sobel, Scharr e Laplacian. As respectivas funções são: cv2.Sobel(), cv2.Scharr(), cv2.Laplacian().\n",
    "\n",
    "## 17. Sobel  \n",
    "Não entraremos na explicação matemática de cada método mas é importante notar que o  Sobel  é  direcional,  então  temos  que  juntar  o  filtro  horizontal  e  o  vertical  para  ter  uma\n",
    "transformação completa, veja: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a5d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2  \n",
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  \n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0) \n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1) \n",
    "sobelX = np.uint8(np.absolute(sobelX)) \n",
    "sobelY = np.uint8(np.absolute(sobelY)) \n",
    "sobel = cv2.bitwise_or(sobelX, sobelY)  \n",
    "resultado = np.vstack([  np.hstack([img,    sobelX]),  np.hstack([sobelY, sobel])  ])   \n",
    "cv2.imshow(\"Sobel\", resultado) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06af17",
   "metadata": {},
   "source": [
    "Note  que  devido  ao  processamento  do  Sobel  é  preciso  trabalhar  com  a  imagem  com ponto  flutuante  de  64  bits  (que  suporta  valores  positivos  e  negativos)  para  depois  converter\n",
    "para uint8 novamente.\n",
    "\n",
    "\n",
    "\n",
    "**Figura 28 Da esquerda para a direta e de cima para baixo temos: a imagem original, Sobel Horizontal (sobelX), Sobel Vertical (sobelY) e a imagem com o Sobel combinado que é o resultado final.**\n",
    "\n",
    "## 18. Filtro Laplaciano\n",
    "O  filtro  Laplaciano  não  exige  processamento  individual  horizontal  e  vertical  como  o Sobel.  Um  único  passo  é  necessário  para  gerar  a  imagem  abaixo.  Contudo,  também  é \n",
    "\n",
    "necessário trabalhar com a representação do pixel em ponto flutuant de 64 bits com sinal para depois converter novamente para inteiro sem sinal de 8 bits. \n",
    "\n",
    "\n",
    "\n",
    "**Figura 29 Filtro Laplaciano.**\n",
    "\n",
    "O código segue abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "lap = cv2.Laplacian(img, cv2.CV_64F) \n",
    "lap = np.uint8(np.absolute(lap)) \n",
    "resultado = np.vstack([img, lap])  \n",
    "cv2.imshow(\"Filtro Laplaciano\", resultado) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99a836",
   "metadata": {},
   "source": [
    "## 19. Detector de bordas Canny  \n",
    "Em inglês canny pode ser traduzido para esperto, esta no discionário. E o Carry Hedge Detector ou detector de bordas Caany realmente é mais inteligente que os outros. Na verdade \n",
    "\n",
    "ele  se  utiliza  de  outras  técnicas  como  o  Sobel  e  realiza  multiplos  passos  para  chegar  ao resultado final.  \n",
    "\n",
    "Basicamente o Canny envolve: \n",
    "\n",
    "1. Aplicar um filtro gaussiano para suavizar a imagem e remover o ruído. \n",
    "\n",
    "2. Encontrar os gradientes de intensidade da imagem. \n",
    "\n",
    "3. Aplicar Sobel duplo para determinar bordas potenciais. \n",
    "\n",
    "4. Aplicar o processo de “hysteresis” para verificar se o pixel faz parte de uma borda  “forte”  suprimindo todas as outras bordas que são fracas e não conectadas a bordas fortes.  \n",
    "\n",
    "É preciso fornecer dois parâmetros para a função  cv2.Canny(). Esses dois valores são o  limiar  1  e  limiar  2  e são utilizados no processo de “hysteresis” final.  Qualquer  gradiente \n",
    "\n",
    "com valor maior que o limiar 2 é considerado como borda. Qualquer valor inferior ao limiar 1 não é considerado borda. Valores entre o limiar 1 e limiar 2 são classificados como bordas ou \n",
    "\n",
    "não bordas com base em como eles estão conectados.  \n",
    "\n",
    "\n",
    "\n",
    "**Figura 30 Filtro canny com parâmetros diferentes. A esquerda deixamos um limiar mais baixo (20,120) e à\n",
    "direita a imagem foi gerada com limiares maiores (70,200).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "img = cv2.imread('ponte.jpg') \n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "suave = cv2.GaussianBlur(img, (7, 7), 0)  \n",
    "canny1 = cv2.Canny(suave, 20, 120) \n",
    "canny2 = cv2.Canny(suave, 70, 200) \n",
    "resultado = np.vstack([  np.hstack([img,    suave ]),  np.hstack([canny1, canny2])  ])  \n",
    "cv2.imshow(\"Detector de Bordas Canny\", resultado) \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff890e97",
   "metadata": {},
   "source": [
    "## 20. Identificando e contando objetos\n",
    "Como todos sabem, a atividade de jogar dados é muito útil. Muito útil para jogar RPG, General e outros jogos.  Mas depois do sistema apresentado abaixo, não será mais necessário\n",
    "clicar no mouse ou pressionar uma tecla do teclado para jogar com o computador. Você poderá jogar os dados de verdade e o computador irá “ver” sua pontuação.\n",
    "Para isso precisamos identificar:\n",
    "1. Onde estão os dados na imagem.\n",
    "2. Quantos dados foram jogados.\n",
    "3. Qual é o lado que esta para cima.\n",
    "Inicialmente vamos identificar os dados e contar quantos dados existem na imagem, em um segundo momento iremos identificar quais são esses dados. A imagem que temos esta\n",
    "abaixo. Não é uma imagem fácil pois além dos dados serem vermelhos e terem um contraste menor que dados brancos sobre uma mesa preta, por exemplo, eles ainda estão sobre uma\n",
    "superfície  branca  com  ranhuras,  ou  seja,  não  é  uma  superfície  uniforme.  Isso  irá  dificultar nosso trabalho. \n",
    "\n",
    "\n",
    "\n",
    "**Figura 31 Imagem original. A superfície branca com ranhuras dificultará o processo.** \n",
    "\n",
    "Os passos mostrados na sequência de imagens abaixo são:\n",
    "1. Convertemos a imagem para tons de cinza.\n",
    "2. Aplicamos blur para retirar o ruído e facilitar a identificação das bordas.\n",
    "3. Aplicamos uma binarização na imagem resultando em pixels só brancos e pretos.\n",
    "4. Aplicamos um detector de bordas para identificar os objetos.\n",
    "5. Com as bordas identificadas, vamos contar os contornos externos para achar a\n",
    "quantidade de dados presentes na imagem.\n",
    "\n",
    "\n",
    "\n",
    "**Figura 32 Passos para identificar e contar os dados na imagem.** \n",
    "\n",
    "**Figura 33 Resultado sobre a imagem original.** \n",
    "\n",
    "O código para gerar as saídas acima segue abaixo comentado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adedb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import mahotas  \n",
    "#Função para facilitar a escrita nas imagem \n",
    "def escreve(img, texto, cor=(255,0,0)):\n",
    "  fonte = cv2.FONT_HERSHEY_SIMPLEX \n",
    "  cv2.putText(img, texto, (10,20), fonte, 0.5, cor, 0,      cv2.LINE_AA)\n",
    "\n",
    "imgColorida = cv2.imread('data/dados.png') #Carregamento da imagem  \n",
    "#Se necessário o redimensioamento da imagem pode vir aqui.\n",
    "#Passo 1: Conversão para tons de cinza \n",
    "img = cv2.cvtColor(imgColorida, cv2.COLOR_BGR2GRAY)  \n",
    "#Passo 2: Blur/Suavização da imagem \n",
    "suave = cv2.blur(img, (7, 7))  \n",
    "#Passo 3: Binarização resultando em pixels brancos e pretos \n",
    "T = mahotas.thresholding.otsu(suave) \n",
    "bin = suave.copy()\n",
    "bin[bin > T] = 255 \n",
    "bin[bin < 255] = 0 \n",
    "bin = cv2.bitwise_not(bin)  \n",
    "#Passo 4: Detecção de bordas com Canny \n",
    "bordas = cv2.Canny(bin, 70, 150)  \n",
    "#Passo 5: Identificação e contagem dos contornos da imagem \n",
    "#cv2.RETR_EXTERNAL = conta apenas os contornos externos \n",
    "(objetos, lx) = cv2.findContours(bordas.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #A variável lx (lixo) recebe dados que não são utilizados\n",
    "escreve(img, \"Imagem em tons de cinza\", 0) \n",
    "escreve(suave, \"Suavizacao com Blur\", 0) \n",
    "escreve(bin, \"Binarizacao com Metodo Otsu\", 255) \n",
    "escreve(bordas, \"Detector de bordas Canny\", 255)\n",
    "temp = np.vstack([  np.hstack([img, suave]),   np.hstack([bin, bordas])   ])   \n",
    "#cv2.imshow(\"Quantidade de objetos: \"+str(len(objetos)), temp) \n",
    "ut.show_img(temp) \n",
    " \n",
    "\n",
    "imgC2 = imgColorida.copy() \n",
    "#cv2.imshow(\"Imagem Original\", imgColorida)\n",
    "ut.show_img(imgColorida)\n",
    "\n",
    "cv2.drawContours(imgC2, objetos, -1, (255, 0, 0), 2) \n",
    "escreve(imgC2, str(len(objetos))+\" objetos encontrados!\") \n",
    "\n",
    "#cv2.imshow(\"Resultado\", imgC2) \n",
    "ut.show_img(imgC2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f3c905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import mahotas  \n",
    "\n",
    "\n",
    "#Função para facilitar a escrita nas imagem \n",
    "def escreve(img, texto, cor=(255,0,0)):\n",
    "    fonte = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    cv2.putText(img, texto, (10,20), fonte, 0.5, cor, 0, cv2.LINE_AA)\n",
    "\n",
    "imgColorida = cv2.imread('dados.jpg') #Carregamento da imagem\n",
    "\n",
    "#Se necessário o redimensioamento da imagem pode vir aqui.\n",
    "\n",
    "#Passo 1: Conversão para tons de cinza \n",
    "img = cv2.cvtColor(imgColorida, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "#Passo 2: Blur/Suavização da imagem \n",
    "suave = cv2.blur(img, (7, 7))  \n",
    "\n",
    "#Passo 3: Binarização resultando em pixels brancos e pretos \n",
    "T = mahotas.thresholding.otsu(suave) \n",
    "bin = suave.copy()\n",
    "bin[bin > T] = 255 \n",
    "bin[bin < 255] = 0 \n",
    "bin = cv2.bitwise_not(bin)  \n",
    "\n",
    "#Passo 4: Detecção de bordas com Canny \n",
    "bordas = cv2.Canny(bin, 70, 150)  \n",
    "\n",
    "#Passo 5: Identificação e contagem dos contornos da imagem \n",
    "#cv2.RETR_EXTERNAL = conta apenas os contornos externos \n",
    "(lx, objetos, lx) = cv2.findContours(bordas.copy(),cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "#A variável lx (lixo) recebe dados que não são utilizados\n",
    "\n",
    "escreve(img, \"Imagem em tons de cinza\", 0) \n",
    "escreve(suave, \"Suavizacao com Blur\", 0) \n",
    "escreve(bin, \"Binarizacao com Metodo Otsu\", 255) \n",
    "escreve(bordas, \"Detector de bordas Canny\", 255)\n",
    "temp = np.vstack([\n",
    "    np.hstack([img, suave]), \n",
    "    np.hstack([bin, bordas])\n",
    "    ])   \n",
    "cv2.imshow(\"Quantidade de objetos: \"+str(len(objetos)), temp) \n",
    "cv2.waitKey(0) \n",
    "imgC2 = imgColorida.copy() \n",
    "cv2.imshow(\"Imagem Original\", imgColorida)\n",
    "cv2.drawContours(imgC2, objetos, -1, (255, 0, 0), 2) \n",
    "escreve(imgC2, str(len(objetos))+\" objetos encontrados!\") \n",
    "cv2.imshow(\"Resultado\", imgC2) \n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e6783",
   "metadata": {},
   "source": [
    "A função cv2.findContours() não foi mostrada anteriormente neste tutorial. Encorajamos o leitor a buscar compreender melhor a função na documentação da OpenCV. Resumidamente\n",
    "ela busca na imagem contornos fechados e retorna um mapa que é um vetor contendo os objetos encontrados. Este mapa neste caso foi armazenado na variável ‘objetos’.\n",
    "É por isso que usamos a função len(objetos) para contar quantos objetos foram encontrados. O terceiro argumento definido como -1 define que todos os contornos de\n",
    "‘objetos’ serão desenhados. Mas podemos identificar um contorno especifico sendo ‘0’ para o primeiro objeto, ‘1’ para o segudo e assim por diante.Agora é preciso identificar qual é o lado do dado que esta virado para cima. Para isso precisaremos contar quantos pontos brancos existe na superfície do dado. É possível utilizar várias técnicas para encontrar a solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db1a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a67ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da30c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8efbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f32802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8bdda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f0ef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5492048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d005f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e11b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
